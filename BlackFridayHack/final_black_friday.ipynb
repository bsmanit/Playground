{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\"Product_ID\",\"Gender\",\"Age\",\"Occupation\",\"City_Category\",\"Stay_In_Current_City_Years\",\n",
    "                       \"Marital_Status\",\"Product_Category_1\",\"Product_Category_2\",\"Product_Category_3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.array(train[\"Purchase\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train.copy()\n",
    "test_X = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.fillna(-999)\n",
    "test_X = test_X.fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding count feature \n",
    "from collections import Counter\n",
    "\n",
    "#change directly in df\n",
    "def count_feature(df_train=None, df_test=None , column=None):\n",
    "    count_dict = Counter(df_train[column]) \n",
    "    \n",
    "    if 'count_'+column not in df_train.columns:\n",
    "        df_train['count_'+column] = df_train[column].map(count_dict)\n",
    "        df_test['count_'+column] = df_test[column].map(count_dict)\n",
    "    else:\n",
    "        print(\"feature already present :{}\".format('count_'+column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_feature(train_X,test_X, \"User_ID\" )\n",
    "count_feature(train_X,test_X, \"Product_ID\" )\n",
    "count_feature(train_X,test_X, \"Occupation\" )\n",
    "count_feature(train_X,test_X, \"Marital_Status\" )\n",
    "count_feature(train_X,test_X,  \"Product_Category_1\")\n",
    "count_feature(train_X,test_X,  \"Product_Category_2\")\n",
    "count_feature(train_X,test_X,  \"Product_Category_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Purchase</th>\n",
       "      <th>count_User_ID</th>\n",
       "      <th>count_Product_ID</th>\n",
       "      <th>count_Occupation</th>\n",
       "      <th>count_Marital_Status</th>\n",
       "      <th>count_Product_Category_1</th>\n",
       "      <th>count_Product_Category_2</th>\n",
       "      <th>count_Product_Category_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00069042</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>8370</td>\n",
       "      <td>35</td>\n",
       "      <td>227</td>\n",
       "      <td>12930</td>\n",
       "      <td>324731</td>\n",
       "      <td>20213</td>\n",
       "      <td>173638</td>\n",
       "      <td>383247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00248942</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15200</td>\n",
       "      <td>35</td>\n",
       "      <td>581</td>\n",
       "      <td>12930</td>\n",
       "      <td>324731</td>\n",
       "      <td>140378</td>\n",
       "      <td>16466</td>\n",
       "      <td>18428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00087842</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1422</td>\n",
       "      <td>35</td>\n",
       "      <td>102</td>\n",
       "      <td>12930</td>\n",
       "      <td>324731</td>\n",
       "      <td>3947</td>\n",
       "      <td>173638</td>\n",
       "      <td>383247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00085442</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1057</td>\n",
       "      <td>35</td>\n",
       "      <td>341</td>\n",
       "      <td>12930</td>\n",
       "      <td>324731</td>\n",
       "      <td>3947</td>\n",
       "      <td>55108</td>\n",
       "      <td>383247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000002</td>\n",
       "      <td>P00285442</td>\n",
       "      <td>M</td>\n",
       "      <td>55+</td>\n",
       "      <td>16</td>\n",
       "      <td>C</td>\n",
       "      <td>4+</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>7969</td>\n",
       "      <td>77</td>\n",
       "      <td>203</td>\n",
       "      <td>25371</td>\n",
       "      <td>324731</td>\n",
       "      <td>113925</td>\n",
       "      <td>173638</td>\n",
       "      <td>383247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID Product_ID Gender   Age  Occupation City_Category  \\\n",
       "0  1000001  P00069042      F  0-17          10             A   \n",
       "1  1000001  P00248942      F  0-17          10             A   \n",
       "2  1000001  P00087842      F  0-17          10             A   \n",
       "3  1000001  P00085442      F  0-17          10             A   \n",
       "4  1000002  P00285442      M   55+          16             C   \n",
       "\n",
       "  Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
       "0                          2               0                   3   \n",
       "1                          2               0                   1   \n",
       "2                          2               0                  12   \n",
       "3                          2               0                  12   \n",
       "4                         4+               0                   8   \n",
       "\n",
       "   Product_Category_2  Product_Category_3  Purchase  count_User_ID  \\\n",
       "0              -999.0              -999.0      8370             35   \n",
       "1                 6.0                14.0     15200             35   \n",
       "2              -999.0              -999.0      1422             35   \n",
       "3                14.0              -999.0      1057             35   \n",
       "4              -999.0              -999.0      7969             77   \n",
       "\n",
       "   count_Product_ID  count_Occupation  count_Marital_Status  \\\n",
       "0               227             12930                324731   \n",
       "1               581             12930                324731   \n",
       "2               102             12930                324731   \n",
       "3               341             12930                324731   \n",
       "4               203             25371                324731   \n",
       "\n",
       "   count_Product_Category_1  count_Product_Category_2  \\\n",
       "0                     20213                    173638   \n",
       "1                    140378                     16466   \n",
       "2                      3947                    173638   \n",
       "3                      3947                     55108   \n",
       "4                    113925                    173638   \n",
       "\n",
       "   count_Product_Category_3  \n",
       "0                    383247  \n",
       "1                     18428  \n",
       "2                    383247  \n",
       "3                    383247  \n",
       "4                    383247  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manual method in aggregate \n",
    "\n",
    "def percentile(n):\n",
    "    def percentile_(x):\n",
    "        return np.percentile(x, n)\n",
    "    percentile_.__name__ = 'percentile_%s' % n\n",
    "    return percentile_\n",
    "\n",
    "\n",
    "#X_train.groupby('User_ID').agg({'Product_Category_1' : ['min', 'max', 'mean', percentile(0.25), percentile(0.75)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train_X.groupby('Product_ID').agg({'Purchase' : ['min', 'max', 'mean', percentile(0.25), percentile(0.75) ]})\n",
    "\n",
    "temp.columns = ['Product_Purchase_min', \"Product_Purchase_max\", \"Product_Purchase_mean\",\n",
    "                \"Product_Purchase_per_25\", \"Product_Purchase_per_75\"]\n",
    "\n",
    "X_train = pd.merge(train_X,temp.reset_index(), how='left', left_on=\"Product_ID\", right_on=\"Product_ID\")\n",
    "X_test =  pd.merge(test_X,temp.reset_index(), how='left', left_on=\"Product_ID\", right_on=\"Product_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train_X.groupby('User_ID').agg({'User_ID' : ['min', 'max', 'mean', percentile(0.25), percentile(0.75) ]})\n",
    "\n",
    "temp.columns = ['User_Purchase_min', \"User_Purchase_max\", \"User_Purchase_mean\",\n",
    "                \"User_Purchase_per_25\", \"User_Purchase_per_75\"]\n",
    "\n",
    "X_train = pd.merge(train_X,temp.reset_index(), how='left', left_on=\"User_ID\", right_on=\"User_ID\")\n",
    "X_test =  pd.merge(test_X,temp.reset_index(), how='left', left_on=\"User_ID\", right_on=\"User_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>...</th>\n",
       "      <th>count_Occupation</th>\n",
       "      <th>count_Marital_Status</th>\n",
       "      <th>count_Product_Category_1</th>\n",
       "      <th>count_Product_Category_2</th>\n",
       "      <th>count_Product_Category_3</th>\n",
       "      <th>User_Purchase_min</th>\n",
       "      <th>User_Purchase_max</th>\n",
       "      <th>User_Purchase_mean</th>\n",
       "      <th>User_Purchase_per_25</th>\n",
       "      <th>User_Purchase_per_75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00069042</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12930</td>\n",
       "      <td>324731</td>\n",
       "      <td>20213</td>\n",
       "      <td>173638</td>\n",
       "      <td>383247</td>\n",
       "      <td>1000001</td>\n",
       "      <td>1000001</td>\n",
       "      <td>1000001</td>\n",
       "      <td>1000001.0</td>\n",
       "      <td>1000001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00248942</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12930</td>\n",
       "      <td>324731</td>\n",
       "      <td>140378</td>\n",
       "      <td>16466</td>\n",
       "      <td>18428</td>\n",
       "      <td>1000001</td>\n",
       "      <td>1000001</td>\n",
       "      <td>1000001</td>\n",
       "      <td>1000001.0</td>\n",
       "      <td>1000001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00087842</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12930</td>\n",
       "      <td>324731</td>\n",
       "      <td>3947</td>\n",
       "      <td>173638</td>\n",
       "      <td>383247</td>\n",
       "      <td>1000001</td>\n",
       "      <td>1000001</td>\n",
       "      <td>1000001</td>\n",
       "      <td>1000001.0</td>\n",
       "      <td>1000001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00085442</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12930</td>\n",
       "      <td>324731</td>\n",
       "      <td>3947</td>\n",
       "      <td>55108</td>\n",
       "      <td>383247</td>\n",
       "      <td>1000001</td>\n",
       "      <td>1000001</td>\n",
       "      <td>1000001</td>\n",
       "      <td>1000001.0</td>\n",
       "      <td>1000001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000002</td>\n",
       "      <td>P00285442</td>\n",
       "      <td>M</td>\n",
       "      <td>55+</td>\n",
       "      <td>16</td>\n",
       "      <td>C</td>\n",
       "      <td>4+</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25371</td>\n",
       "      <td>324731</td>\n",
       "      <td>113925</td>\n",
       "      <td>173638</td>\n",
       "      <td>383247</td>\n",
       "      <td>1000002</td>\n",
       "      <td>1000002</td>\n",
       "      <td>1000002</td>\n",
       "      <td>1000002.0</td>\n",
       "      <td>1000002.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID Product_ID Gender   Age  Occupation City_Category  \\\n",
       "0  1000001  P00069042      F  0-17          10             A   \n",
       "1  1000001  P00248942      F  0-17          10             A   \n",
       "2  1000001  P00087842      F  0-17          10             A   \n",
       "3  1000001  P00085442      F  0-17          10             A   \n",
       "4  1000002  P00285442      M   55+          16             C   \n",
       "\n",
       "  Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
       "0                          2               0                   3   \n",
       "1                          2               0                   1   \n",
       "2                          2               0                  12   \n",
       "3                          2               0                  12   \n",
       "4                         4+               0                   8   \n",
       "\n",
       "   Product_Category_2          ...           count_Occupation  \\\n",
       "0              -999.0          ...                      12930   \n",
       "1                 6.0          ...                      12930   \n",
       "2              -999.0          ...                      12930   \n",
       "3                14.0          ...                      12930   \n",
       "4              -999.0          ...                      25371   \n",
       "\n",
       "   count_Marital_Status  count_Product_Category_1  count_Product_Category_2  \\\n",
       "0                324731                     20213                    173638   \n",
       "1                324731                    140378                     16466   \n",
       "2                324731                      3947                    173638   \n",
       "3                324731                      3947                     55108   \n",
       "4                324731                    113925                    173638   \n",
       "\n",
       "   count_Product_Category_3  User_Purchase_min  User_Purchase_max  \\\n",
       "0                    383247            1000001            1000001   \n",
       "1                     18428            1000001            1000001   \n",
       "2                    383247            1000001            1000001   \n",
       "3                    383247            1000001            1000001   \n",
       "4                    383247            1000002            1000002   \n",
       "\n",
       "   User_Purchase_mean  User_Purchase_per_25  User_Purchase_per_75  \n",
       "0             1000001             1000001.0             1000001.0  \n",
       "1             1000001             1000001.0             1000001.0  \n",
       "2             1000001             1000001.0             1000001.0  \n",
       "3             1000001             1000001.0             1000001.0  \n",
       "4             1000002             1000002.0             1000002.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def label_encoding(df_train=None, df_test=None , var=None):\n",
    "#    lb = preprocessing.LabelEncoder()\n",
    "#    full_var_data = pd.concat((df_train[var],df_test[var]),axis=0)\n",
    "#    lb.fit( full_var_data )\n",
    "#    df_train[var] = lb.transform(df_train[var])\n",
    "#    df_test[var] = lb.transform(df_test[var])\n",
    "\n",
    "\n",
    "#label_encoding(train_X,test_X, \"Product_ID\" )\n",
    "#label_encoding(train_X,test_X, \"Gender\" )\n",
    "#label_encoding(train_X,test_X, \"City_Category\" )\n",
    "#label_encoding(train_X,test_X, \"Occupation\" ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User_ID                         int64\n",
       "Product_ID                     object\n",
       "Gender                         object\n",
       "Age                            object\n",
       "Occupation                      int64\n",
       "City_Category                  object\n",
       "Stay_In_Current_City_Years     object\n",
       "Marital_Status                  int64\n",
       "Product_Category_1              int64\n",
       "Product_Category_2            float64\n",
       "Product_Category_3            float64\n",
       "Purchase                        int64\n",
       "count_User_ID                   int64\n",
       "count_Product_ID                int64\n",
       "count_Occupation                int64\n",
       "count_Marital_Status            int64\n",
       "count_Product_Category_1        int64\n",
       "count_Product_Category_2        int64\n",
       "count_Product_Category_3        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\"Product_ID\",\"Gender\",\"Age\",\"Occupation\",\"City_Category\",\"Stay_In_Current_City_Years\",\n",
    "                       \"Marital_Status\",\"Product_Category_1\",\"Product_Category_2\",\"Product_Category_3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Occupation Marital_Status  Product_Category_1\n",
    "train_X[\"Occupation\"] = train_X[\"Occupation\"].astype('object')\n",
    "train_X[\"Marital_Status\"] = train_X[\"Marital_Status\"].astype('object')\n",
    "train_X[\"Product_Category_1\"] = train_X[\"Product_Category_1\"].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product_ID\n",
      "Gender\n",
      "Age\n",
      "Occupation\n",
      "City_Category\n",
      "Stay_In_Current_City_Years\n",
      "Marital_Status\n",
      "Product_Category_1\n",
      "Product_Category_2\n",
      "Product_Category_3\n"
     ]
    }
   ],
   "source": [
    "for var in categorical_columns:\n",
    "    lb = preprocessing.LabelEncoder()\n",
    "    print(var)\n",
    "    full_var_data = pd.concat((train_X[var],test_X[var]),axis=0)\n",
    "    lb.fit( full_var_data )\n",
    "    train_X[var] = lb.transform(train_X[var])\n",
    "    test_X[var] = lb.transform(test_X[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-203-b1df3e84bc76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping the unnecessary columns from IDVs ##\n",
    "train_X = np.array( train_X.drop(['Purchase'],axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params[\"objective\"] = \"reg:linear\"\n",
    "params[\"eta\"] = 0.05\n",
    "params[\"seed\"] = 0\n",
    "plst = list(params.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "num_rounds = 5667 \n",
    "\n",
    "#pass ndarray\n",
    "def manual_cv(X, y, X_test):\n",
    "    kf = KFold(n_splits=3,shuffle=True,random_state=123)\n",
    "    \n",
    "    fold_score = {}\n",
    "    k = 0\n",
    "    \n",
    "    y_test_fold = {}\n",
    "    model_fold= {}\n",
    "    for train_index, test_index in kf.split(X,y):\n",
    "        X_model = X[train_index]\n",
    "        y_model = y[train_index]\n",
    "        X_val   = X[test_index]\n",
    "        y_val   = y[test_index]\n",
    "        \n",
    "        #to hold test prediction per fold\n",
    "        \n",
    "        \n",
    "        X_model_xgb = xgb.DMatrix(X_model, label=y_model, missing = -999)\n",
    "        X_val_xgb =  xgb.DMatrix(X_val, label=y_val, missing = -999)\n",
    "        \n",
    "        x_test_xgb = xgb.DMatrix(X_test, missing = -999)\n",
    "        \n",
    "        watchlist = [ (X_model_xgb,'train'), (X_val_xgb,'eval')] #more than one will use last\n",
    "        \n",
    "        bst =  xgb.train(plst,X_model_xgb, num_rounds ,early_stopping_rounds=10, evals=watchlist, verbose_eval=10) #\n",
    "        \n",
    "        y_predict = bst.predict(X_val_xgb, ntree_limit=bst.best_ntree_limit) \n",
    "        y_test = bst.predict(x_test_xgb, ntree_limit=bst.best_ntree_limit)\n",
    "        \n",
    "        y_predict_train = bst.predict(X_model_xgb, ntree_limit=bst.best_ntree_limit)\n",
    "        \n",
    "        test_error = np.sqrt(mean_squared_error(y_val, y_predict))\n",
    "        train_error = np.sqrt(mean_squared_error(y_model,  y_predict_train))\n",
    "        \n",
    "        \n",
    "        print(\"train_rmse :{}\\t test_score:{}\".format(train_error, test_error))\n",
    "        \n",
    "        y_test_fold[k] = y_test\n",
    "        \n",
    "        model_fold[k] = bst\n",
    "                \n",
    "        fold_score[k] = test_error\n",
    "        k+=1\n",
    "    return model_fold, fold_score, y_test_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgtrain = xgb.DMatrix(train_X, label=train_y, missing = -999)\n",
    "#xgtest = xgb.DMatrix(test_X,missing = -999)\n",
    "#num_rounds = 5667\n",
    "#model = xgb.train(plst, xgtrain, num_rounds)\n",
    "#pred_test_y_xgb1 = model.predict(xgtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'drop'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-235-c0667b1805a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Purchase'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'drop'"
     ]
    }
   ],
   "source": [
    "test_X = np.array( test_X.drop(['Purchase'],axis=1, errors='ignore') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:10068.7\teval-rmse:10047.4\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 10 rounds.\n",
      "[10]\ttrain-rmse:6465.44\teval-rmse:6450.04\n",
      "[20]\ttrain-rmse:4484.65\teval-rmse:4473.77\n",
      "[30]\ttrain-rmse:3500.05\teval-rmse:3493.43\n",
      "[40]\ttrain-rmse:3059.93\teval-rmse:3057.35\n",
      "[50]\ttrain-rmse:2876.09\teval-rmse:2876.65\n",
      "[60]\ttrain-rmse:2797.63\teval-rmse:2800.97\n",
      "[70]\ttrain-rmse:2760.43\teval-rmse:2765.71\n",
      "[80]\ttrain-rmse:2740.69\teval-rmse:2747.85\n",
      "[90]\ttrain-rmse:2727.99\teval-rmse:2736.61\n",
      "[100]\ttrain-rmse:2717.96\teval-rmse:2727.98\n",
      "[110]\ttrain-rmse:2710.98\teval-rmse:2722.29\n",
      "[120]\ttrain-rmse:2704.55\teval-rmse:2717.08\n",
      "[130]\ttrain-rmse:2699.13\teval-rmse:2712.85\n",
      "[140]\ttrain-rmse:2693.02\teval-rmse:2707.89\n",
      "[150]\ttrain-rmse:2687.64\teval-rmse:2703.55\n",
      "[160]\ttrain-rmse:2680.3\teval-rmse:2697.17\n",
      "[170]\ttrain-rmse:2674.88\teval-rmse:2692.67\n",
      "[180]\ttrain-rmse:2669.67\teval-rmse:2688.5\n",
      "[190]\ttrain-rmse:2665.35\teval-rmse:2685.02\n",
      "[200]\ttrain-rmse:2662.05\teval-rmse:2682.73\n",
      "[210]\ttrain-rmse:2657.21\teval-rmse:2678.84\n",
      "[220]\ttrain-rmse:2653.31\teval-rmse:2675.89\n",
      "[230]\ttrain-rmse:2649.18\teval-rmse:2672.83\n",
      "[240]\ttrain-rmse:2644.82\teval-rmse:2669.38\n",
      "[250]\ttrain-rmse:2640.76\teval-rmse:2666.12\n",
      "[260]\ttrain-rmse:2636.05\teval-rmse:2662.38\n",
      "[270]\ttrain-rmse:2631.77\teval-rmse:2659.02\n",
      "[280]\ttrain-rmse:2628.1\teval-rmse:2656.07\n",
      "[290]\ttrain-rmse:2624.35\teval-rmse:2653.15\n",
      "[300]\ttrain-rmse:2619.66\teval-rmse:2649.05\n",
      "[310]\ttrain-rmse:2615.57\teval-rmse:2645.79\n",
      "[320]\ttrain-rmse:2612.03\teval-rmse:2643\n",
      "[330]\ttrain-rmse:2607.94\teval-rmse:2639.69\n",
      "[340]\ttrain-rmse:2604.72\teval-rmse:2637.45\n",
      "[350]\ttrain-rmse:2601.4\teval-rmse:2635.11\n",
      "[360]\ttrain-rmse:2598.22\teval-rmse:2632.6\n",
      "[370]\ttrain-rmse:2594.6\teval-rmse:2629.91\n",
      "[380]\ttrain-rmse:2591.48\teval-rmse:2627.64\n",
      "[390]\ttrain-rmse:2587.56\teval-rmse:2624.72\n",
      "[400]\ttrain-rmse:2583.61\teval-rmse:2621.67\n",
      "[410]\ttrain-rmse:2580.47\teval-rmse:2619.34\n",
      "[420]\ttrain-rmse:2577.96\teval-rmse:2617.86\n",
      "[430]\ttrain-rmse:2574.97\teval-rmse:2615.88\n",
      "[440]\ttrain-rmse:2572.56\teval-rmse:2614.36\n",
      "[450]\ttrain-rmse:2569.86\teval-rmse:2612.61\n",
      "[460]\ttrain-rmse:2567.66\teval-rmse:2611.29\n",
      "[470]\ttrain-rmse:2564.31\teval-rmse:2608.71\n",
      "[480]\ttrain-rmse:2562.05\teval-rmse:2607.27\n",
      "[490]\ttrain-rmse:2558.85\teval-rmse:2604.87\n",
      "[500]\ttrain-rmse:2555.59\teval-rmse:2602.49\n",
      "[510]\ttrain-rmse:2552.88\teval-rmse:2600.66\n",
      "[520]\ttrain-rmse:2551.39\teval-rmse:2600.04\n",
      "[530]\ttrain-rmse:2549.16\teval-rmse:2598.75\n",
      "[540]\ttrain-rmse:2546.81\teval-rmse:2597.1\n",
      "[550]\ttrain-rmse:2545.13\teval-rmse:2596.18\n",
      "[560]\ttrain-rmse:2542.58\teval-rmse:2594.41\n",
      "[570]\ttrain-rmse:2539.5\teval-rmse:2592.21\n",
      "[580]\ttrain-rmse:2536.59\teval-rmse:2590.21\n",
      "[590]\ttrain-rmse:2534.04\teval-rmse:2588.57\n",
      "[600]\ttrain-rmse:2531.78\teval-rmse:2587.12\n",
      "[610]\ttrain-rmse:2529.51\teval-rmse:2585.66\n",
      "[620]\ttrain-rmse:2526.96\teval-rmse:2584.2\n",
      "[630]\ttrain-rmse:2525.02\teval-rmse:2583.1\n",
      "[640]\ttrain-rmse:2523.13\teval-rmse:2582.17\n",
      "[650]\ttrain-rmse:2521.17\teval-rmse:2580.95\n",
      "[660]\ttrain-rmse:2519.14\teval-rmse:2579.66\n",
      "[670]\ttrain-rmse:2516.6\teval-rmse:2577.93\n",
      "[680]\ttrain-rmse:2514.38\teval-rmse:2576.57\n",
      "[690]\ttrain-rmse:2512.76\teval-rmse:2575.74\n",
      "[700]\ttrain-rmse:2511.08\teval-rmse:2574.8\n",
      "[710]\ttrain-rmse:2509.27\teval-rmse:2573.8\n",
      "[720]\ttrain-rmse:2507.17\teval-rmse:2572.48\n",
      "[730]\ttrain-rmse:2505.93\teval-rmse:2571.91\n",
      "[740]\ttrain-rmse:2504.21\teval-rmse:2571.1\n",
      "[750]\ttrain-rmse:2502.05\teval-rmse:2569.89\n",
      "[760]\ttrain-rmse:2500.08\teval-rmse:2568.72\n",
      "[770]\ttrain-rmse:2497.67\teval-rmse:2567.13\n",
      "[780]\ttrain-rmse:2495.57\teval-rmse:2565.99\n",
      "[790]\ttrain-rmse:2493.69\teval-rmse:2564.98\n",
      "[800]\ttrain-rmse:2492.17\teval-rmse:2564.29\n",
      "[810]\ttrain-rmse:2490.02\teval-rmse:2562.96\n",
      "[820]\ttrain-rmse:2488.43\teval-rmse:2562.24\n",
      "[830]\ttrain-rmse:2486.71\teval-rmse:2561.42\n",
      "[840]\ttrain-rmse:2484.91\teval-rmse:2560.38\n",
      "[850]\ttrain-rmse:2483.32\teval-rmse:2559.63\n",
      "[860]\ttrain-rmse:2481.51\teval-rmse:2558.58\n",
      "[870]\ttrain-rmse:2479.94\teval-rmse:2557.74\n",
      "[880]\ttrain-rmse:2478.58\teval-rmse:2557.19\n",
      "[890]\ttrain-rmse:2476.95\teval-rmse:2556.32\n",
      "[900]\ttrain-rmse:2474.95\teval-rmse:2555.26\n",
      "[910]\ttrain-rmse:2473.73\teval-rmse:2554.84\n",
      "[920]\ttrain-rmse:2471.94\teval-rmse:2553.82\n",
      "[930]\ttrain-rmse:2470.28\teval-rmse:2552.99\n",
      "[940]\ttrain-rmse:2468.59\teval-rmse:2552.1\n",
      "[950]\ttrain-rmse:2466.97\teval-rmse:2551.27\n",
      "[960]\ttrain-rmse:2465.43\teval-rmse:2550.56\n",
      "[970]\ttrain-rmse:2464.12\teval-rmse:2549.96\n",
      "[980]\ttrain-rmse:2462.34\teval-rmse:2549.01\n",
      "[990]\ttrain-rmse:2461.07\teval-rmse:2548.55\n",
      "[1000]\ttrain-rmse:2459.79\teval-rmse:2548.04\n",
      "[1010]\ttrain-rmse:2458.81\teval-rmse:2547.72\n",
      "[1020]\ttrain-rmse:2457.01\teval-rmse:2546.78\n",
      "[1030]\ttrain-rmse:2455.64\teval-rmse:2546.28\n",
      "[1040]\ttrain-rmse:2454.25\teval-rmse:2545.75\n",
      "[1050]\ttrain-rmse:2453.11\teval-rmse:2545.38\n",
      "[1060]\ttrain-rmse:2451.41\teval-rmse:2544.52\n",
      "[1070]\ttrain-rmse:2449.87\teval-rmse:2543.68\n",
      "[1080]\ttrain-rmse:2448.36\teval-rmse:2543.06\n",
      "[1090]\ttrain-rmse:2447.12\teval-rmse:2542.63\n",
      "[1100]\ttrain-rmse:2445.64\teval-rmse:2542.1\n",
      "[1110]\ttrain-rmse:2444.02\teval-rmse:2541.45\n",
      "[1120]\ttrain-rmse:2442.39\teval-rmse:2540.68\n",
      "[1130]\ttrain-rmse:2441.11\teval-rmse:2540.09\n",
      "[1140]\ttrain-rmse:2439.86\teval-rmse:2539.58\n",
      "[1150]\ttrain-rmse:2438.5\teval-rmse:2538.98\n",
      "[1160]\ttrain-rmse:2437.26\teval-rmse:2538.57\n",
      "[1170]\ttrain-rmse:2435.79\teval-rmse:2538\n",
      "[1180]\ttrain-rmse:2434.25\teval-rmse:2537.4\n",
      "[1190]\ttrain-rmse:2432.76\teval-rmse:2536.77\n",
      "[1200]\ttrain-rmse:2431.07\teval-rmse:2535.9\n",
      "[1210]\ttrain-rmse:2429.52\teval-rmse:2535.21\n",
      "[1220]\ttrain-rmse:2428.21\teval-rmse:2534.78\n",
      "[1230]\ttrain-rmse:2427.22\teval-rmse:2534.45\n",
      "[1240]\ttrain-rmse:2425.69\teval-rmse:2533.59\n",
      "[1250]\ttrain-rmse:2424.43\teval-rmse:2533.07\n",
      "[1260]\ttrain-rmse:2423.32\teval-rmse:2532.74\n",
      "[1270]\ttrain-rmse:2422.07\teval-rmse:2532.23\n",
      "[1280]\ttrain-rmse:2420.74\teval-rmse:2531.7\n",
      "[1290]\ttrain-rmse:2419.85\teval-rmse:2531.5\n",
      "[1300]\ttrain-rmse:2418.55\teval-rmse:2531.02\n",
      "[1310]\ttrain-rmse:2417.16\teval-rmse:2530.42\n",
      "[1320]\ttrain-rmse:2415.83\teval-rmse:2529.89\n",
      "[1330]\ttrain-rmse:2414.59\teval-rmse:2529.4\n",
      "[1340]\ttrain-rmse:2413.44\teval-rmse:2529.01\n",
      "[1350]\ttrain-rmse:2411.85\teval-rmse:2528.15\n",
      "[1360]\ttrain-rmse:2410.48\teval-rmse:2527.59\n",
      "[1370]\ttrain-rmse:2409.11\teval-rmse:2526.98\n",
      "[1380]\ttrain-rmse:2407.8\teval-rmse:2526.41\n",
      "[1390]\ttrain-rmse:2406.63\teval-rmse:2526.01\n",
      "[1400]\ttrain-rmse:2405.6\teval-rmse:2525.83\n",
      "[1410]\ttrain-rmse:2404.69\teval-rmse:2525.65\n",
      "[1420]\ttrain-rmse:2403.34\teval-rmse:2525.14\n",
      "[1430]\ttrain-rmse:2402.11\teval-rmse:2524.69\n",
      "[1440]\ttrain-rmse:2400.55\teval-rmse:2523.97\n",
      "[1450]\ttrain-rmse:2399.62\teval-rmse:2523.65\n",
      "[1460]\ttrain-rmse:2398.57\teval-rmse:2523.47\n",
      "[1470]\ttrain-rmse:2397.57\teval-rmse:2523.24\n",
      "[1480]\ttrain-rmse:2396.31\teval-rmse:2522.81\n",
      "[1490]\ttrain-rmse:2395.13\teval-rmse:2522.3\n",
      "[1500]\ttrain-rmse:2393.7\teval-rmse:2521.73\n",
      "[1510]\ttrain-rmse:2392.67\teval-rmse:2521.42\n",
      "[1520]\ttrain-rmse:2391.58\teval-rmse:2521.06\n",
      "[1530]\ttrain-rmse:2390.46\teval-rmse:2520.73\n",
      "[1540]\ttrain-rmse:2389.58\teval-rmse:2520.49\n",
      "[1550]\ttrain-rmse:2388.24\teval-rmse:2519.89\n",
      "[1560]\ttrain-rmse:2387.08\teval-rmse:2519.52\n",
      "[1570]\ttrain-rmse:2385.95\teval-rmse:2519.09\n",
      "[1580]\ttrain-rmse:2384.98\teval-rmse:2518.82\n",
      "[1590]\ttrain-rmse:2383.82\teval-rmse:2518.41\n",
      "[1600]\ttrain-rmse:2382.68\teval-rmse:2518.06\n",
      "[1610]\ttrain-rmse:2381.69\teval-rmse:2517.79\n",
      "[1620]\ttrain-rmse:2380.79\teval-rmse:2517.53\n",
      "[1630]\ttrain-rmse:2379.73\teval-rmse:2517.16\n",
      "[1640]\ttrain-rmse:2379.04\teval-rmse:2517.05\n",
      "[1650]\ttrain-rmse:2378.31\teval-rmse:2516.95\n",
      "[1660]\ttrain-rmse:2377.43\teval-rmse:2516.74\n",
      "[1670]\ttrain-rmse:2376.29\teval-rmse:2516.25\n",
      "[1680]\ttrain-rmse:2375.15\teval-rmse:2515.75\n",
      "[1690]\ttrain-rmse:2374.12\teval-rmse:2515.36\n",
      "[1700]\ttrain-rmse:2372.68\teval-rmse:2514.74\n",
      "[1710]\ttrain-rmse:2371.44\teval-rmse:2514.25\n",
      "[1720]\ttrain-rmse:2370\teval-rmse:2513.6\n",
      "[1730]\ttrain-rmse:2368.97\teval-rmse:2513.29\n",
      "[1740]\ttrain-rmse:2367.67\teval-rmse:2512.83\n",
      "[1750]\ttrain-rmse:2366.76\teval-rmse:2512.57\n",
      "[1760]\ttrain-rmse:2365.72\teval-rmse:2512.24\n",
      "[1770]\ttrain-rmse:2364.89\teval-rmse:2512.09\n",
      "[1780]\ttrain-rmse:2363.74\teval-rmse:2511.74\n",
      "[1790]\ttrain-rmse:2362.42\teval-rmse:2511.23\n",
      "[1800]\ttrain-rmse:2361.17\teval-rmse:2510.7\n",
      "[1810]\ttrain-rmse:2360.27\teval-rmse:2510.47\n",
      "[1820]\ttrain-rmse:2359.15\teval-rmse:2510.04\n",
      "[1830]\ttrain-rmse:2358.33\teval-rmse:2509.9\n",
      "[1840]\ttrain-rmse:2357.32\teval-rmse:2509.62\n",
      "[1850]\ttrain-rmse:2356.27\teval-rmse:2509.35\n",
      "[1860]\ttrain-rmse:2355.31\teval-rmse:2509.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1870]\ttrain-rmse:2354.46\teval-rmse:2508.88\n",
      "[1880]\ttrain-rmse:2353.55\teval-rmse:2508.61\n",
      "[1890]\ttrain-rmse:2352.57\teval-rmse:2508.43\n",
      "[1900]\ttrain-rmse:2351.37\teval-rmse:2508.16\n",
      "[1910]\ttrain-rmse:2350.54\teval-rmse:2507.99\n",
      "[1920]\ttrain-rmse:2349.86\teval-rmse:2507.81\n",
      "[1930]\ttrain-rmse:2348.98\teval-rmse:2507.58\n",
      "[1940]\ttrain-rmse:2347.84\teval-rmse:2507.23\n",
      "[1950]\ttrain-rmse:2346.72\teval-rmse:2506.86\n",
      "[1960]\ttrain-rmse:2345.78\teval-rmse:2506.57\n",
      "[1970]\ttrain-rmse:2344.86\teval-rmse:2506.31\n",
      "[1980]\ttrain-rmse:2343.72\teval-rmse:2505.89\n",
      "[1990]\ttrain-rmse:2342.68\teval-rmse:2505.6\n",
      "[2000]\ttrain-rmse:2341.7\teval-rmse:2505.35\n",
      "[2010]\ttrain-rmse:2340.87\teval-rmse:2505.09\n",
      "[2020]\ttrain-rmse:2339.83\teval-rmse:2504.8\n",
      "[2030]\ttrain-rmse:2338.78\teval-rmse:2504.55\n",
      "[2040]\ttrain-rmse:2337.92\teval-rmse:2504.29\n",
      "[2050]\ttrain-rmse:2336.98\teval-rmse:2504.11\n",
      "[2060]\ttrain-rmse:2336.1\teval-rmse:2503.81\n",
      "[2070]\ttrain-rmse:2335.33\teval-rmse:2503.6\n",
      "[2080]\ttrain-rmse:2334.51\teval-rmse:2503.38\n",
      "[2090]\ttrain-rmse:2333.66\teval-rmse:2503.17\n",
      "[2100]\ttrain-rmse:2332.9\teval-rmse:2503.03\n",
      "[2110]\ttrain-rmse:2331.96\teval-rmse:2502.8\n",
      "[2120]\ttrain-rmse:2330.85\teval-rmse:2502.4\n",
      "[2130]\ttrain-rmse:2329.84\teval-rmse:2502.18\n",
      "[2140]\ttrain-rmse:2328.87\teval-rmse:2501.95\n",
      "[2150]\ttrain-rmse:2328.03\teval-rmse:2501.71\n",
      "[2160]\ttrain-rmse:2327.12\teval-rmse:2501.48\n",
      "[2170]\ttrain-rmse:2326.31\teval-rmse:2501.28\n",
      "[2180]\ttrain-rmse:2325.48\teval-rmse:2501.03\n",
      "[2190]\ttrain-rmse:2324.66\teval-rmse:2500.87\n",
      "[2200]\ttrain-rmse:2323.87\teval-rmse:2500.74\n",
      "[2210]\ttrain-rmse:2322.92\teval-rmse:2500.58\n",
      "[2220]\ttrain-rmse:2322.13\teval-rmse:2500.51\n",
      "[2230]\ttrain-rmse:2321.13\teval-rmse:2500.34\n",
      "[2240]\ttrain-rmse:2320.27\teval-rmse:2500.23\n",
      "[2250]\ttrain-rmse:2319.43\teval-rmse:2500\n",
      "[2260]\ttrain-rmse:2318.57\teval-rmse:2499.77\n",
      "[2270]\ttrain-rmse:2317.88\teval-rmse:2499.67\n",
      "[2280]\ttrain-rmse:2317\teval-rmse:2499.4\n",
      "[2290]\ttrain-rmse:2316.21\teval-rmse:2499.24\n",
      "[2300]\ttrain-rmse:2315.22\teval-rmse:2498.97\n",
      "[2310]\ttrain-rmse:2314.42\teval-rmse:2498.75\n",
      "[2320]\ttrain-rmse:2313.64\teval-rmse:2498.61\n",
      "[2330]\ttrain-rmse:2312.78\teval-rmse:2498.45\n",
      "[2340]\ttrain-rmse:2312\teval-rmse:2498.28\n",
      "[2350]\ttrain-rmse:2311.33\teval-rmse:2498.21\n",
      "[2360]\ttrain-rmse:2310.49\teval-rmse:2498.06\n",
      "[2370]\ttrain-rmse:2309.71\teval-rmse:2497.91\n",
      "[2380]\ttrain-rmse:2308.89\teval-rmse:2497.72\n",
      "[2390]\ttrain-rmse:2308.13\teval-rmse:2497.65\n",
      "[2400]\ttrain-rmse:2307.48\teval-rmse:2497.57\n",
      "[2410]\ttrain-rmse:2306.62\teval-rmse:2497.36\n",
      "[2420]\ttrain-rmse:2305.61\teval-rmse:2497.15\n",
      "[2430]\ttrain-rmse:2304.59\teval-rmse:2496.86\n",
      "[2440]\ttrain-rmse:2303.95\teval-rmse:2496.82\n",
      "[2450]\ttrain-rmse:2303.02\teval-rmse:2496.63\n",
      "[2460]\ttrain-rmse:2302.28\teval-rmse:2496.52\n",
      "[2470]\ttrain-rmse:2301.44\teval-rmse:2496.41\n",
      "[2480]\ttrain-rmse:2300.8\teval-rmse:2496.34\n",
      "[2490]\ttrain-rmse:2300.25\teval-rmse:2496.29\n",
      "[2500]\ttrain-rmse:2299.49\teval-rmse:2496.17\n",
      "[2510]\ttrain-rmse:2298.63\teval-rmse:2495.98\n",
      "[2520]\ttrain-rmse:2298.04\teval-rmse:2495.92\n",
      "[2530]\ttrain-rmse:2297.39\teval-rmse:2495.81\n",
      "[2540]\ttrain-rmse:2296.69\teval-rmse:2495.75\n",
      "[2550]\ttrain-rmse:2295.8\teval-rmse:2495.56\n",
      "[2560]\ttrain-rmse:2294.81\teval-rmse:2495.34\n",
      "[2570]\ttrain-rmse:2294.02\teval-rmse:2495.21\n",
      "[2580]\ttrain-rmse:2293.24\teval-rmse:2495.12\n",
      "[2590]\ttrain-rmse:2292.45\teval-rmse:2494.97\n",
      "[2600]\ttrain-rmse:2291.53\teval-rmse:2494.75\n",
      "[2610]\ttrain-rmse:2290.57\teval-rmse:2494.66\n",
      "[2620]\ttrain-rmse:2289.81\teval-rmse:2494.54\n",
      "[2630]\ttrain-rmse:2288.96\teval-rmse:2494.47\n",
      "[2640]\ttrain-rmse:2288.26\teval-rmse:2494.37\n",
      "[2650]\ttrain-rmse:2287.6\teval-rmse:2494.36\n",
      "[2660]\ttrain-rmse:2286.93\teval-rmse:2494.33\n",
      "[2670]\ttrain-rmse:2286.23\teval-rmse:2494.21\n",
      "[2680]\ttrain-rmse:2285.44\teval-rmse:2494.09\n",
      "[2690]\ttrain-rmse:2284.54\teval-rmse:2493.94\n",
      "[2700]\ttrain-rmse:2283.68\teval-rmse:2493.84\n",
      "[2710]\ttrain-rmse:2282.95\teval-rmse:2493.75\n",
      "[2720]\ttrain-rmse:2282.27\teval-rmse:2493.71\n",
      "[2730]\ttrain-rmse:2281.46\teval-rmse:2493.59\n",
      "[2740]\ttrain-rmse:2280.84\teval-rmse:2493.49\n",
      "[2750]\ttrain-rmse:2280.25\teval-rmse:2493.44\n",
      "[2760]\ttrain-rmse:2279.67\teval-rmse:2493.36\n",
      "[2770]\ttrain-rmse:2278.89\teval-rmse:2493.28\n",
      "[2780]\ttrain-rmse:2278.19\teval-rmse:2493.21\n",
      "[2790]\ttrain-rmse:2277.32\teval-rmse:2492.98\n",
      "[2800]\ttrain-rmse:2276.58\teval-rmse:2492.82\n",
      "[2810]\ttrain-rmse:2275.99\teval-rmse:2492.77\n",
      "[2820]\ttrain-rmse:2275.16\teval-rmse:2492.67\n",
      "[2830]\ttrain-rmse:2274.36\teval-rmse:2492.57\n",
      "[2840]\ttrain-rmse:2273.68\teval-rmse:2492.47\n",
      "[2850]\ttrain-rmse:2272.9\teval-rmse:2492.36\n",
      "[2860]\ttrain-rmse:2272.26\teval-rmse:2492.28\n",
      "[2870]\ttrain-rmse:2271.51\teval-rmse:2492.17\n",
      "[2880]\ttrain-rmse:2270.79\teval-rmse:2492.06\n",
      "[2890]\ttrain-rmse:2269.94\teval-rmse:2491.91\n",
      "[2900]\ttrain-rmse:2269.41\teval-rmse:2491.94\n",
      "[2910]\ttrain-rmse:2268.76\teval-rmse:2491.93\n",
      "Stopping. Best iteration:\n",
      "[2902]\ttrain-rmse:2269.22\teval-rmse:2491.9\n",
      "\n",
      "train_rmse :2269.2220429907657\t test_score:2491.9030071362276\n",
      "[0]\ttrain-rmse:10049.1\teval-rmse:10088.3\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 10 rounds.\n",
      "[10]\ttrain-rmse:6445.55\teval-rmse:6475.92\n",
      "[20]\ttrain-rmse:4476.71\teval-rmse:4501.16\n",
      "[30]\ttrain-rmse:3494.68\teval-rmse:3514.85\n",
      "[40]\ttrain-rmse:3055.59\teval-rmse:3073.21\n",
      "[50]\ttrain-rmse:2872.88\teval-rmse:2889.36\n",
      "[60]\ttrain-rmse:2795.75\teval-rmse:2812.19\n",
      "[70]\ttrain-rmse:2759.39\teval-rmse:2775.87\n",
      "[80]\ttrain-rmse:2739.69\teval-rmse:2756.41\n",
      "[90]\ttrain-rmse:2726.11\teval-rmse:2743.54\n",
      "[100]\ttrain-rmse:2716.25\teval-rmse:2734.37\n",
      "[110]\ttrain-rmse:2708.09\teval-rmse:2726.87\n",
      "[120]\ttrain-rmse:2701.99\teval-rmse:2721.39\n",
      "[130]\ttrain-rmse:2695.09\teval-rmse:2715.16\n",
      "[140]\ttrain-rmse:2688.66\teval-rmse:2709.7\n",
      "[150]\ttrain-rmse:2683.03\teval-rmse:2705.13\n",
      "[160]\ttrain-rmse:2677.63\teval-rmse:2700.67\n",
      "[170]\ttrain-rmse:2670.77\teval-rmse:2694.89\n",
      "[180]\ttrain-rmse:2664.58\teval-rmse:2689.58\n",
      "[190]\ttrain-rmse:2658.68\teval-rmse:2684.59\n",
      "[200]\ttrain-rmse:2654.64\teval-rmse:2681.45\n",
      "[210]\ttrain-rmse:2649.68\teval-rmse:2677.55\n",
      "[220]\ttrain-rmse:2645.12\teval-rmse:2673.79\n",
      "[230]\ttrain-rmse:2641.47\teval-rmse:2671.09\n",
      "[240]\ttrain-rmse:2636.62\teval-rmse:2667.36\n",
      "[250]\ttrain-rmse:2633.25\teval-rmse:2665.02\n",
      "[260]\ttrain-rmse:2628.39\teval-rmse:2661.02\n",
      "[270]\ttrain-rmse:2623.8\teval-rmse:2657.3\n",
      "[280]\ttrain-rmse:2620.39\teval-rmse:2654.82\n",
      "[290]\ttrain-rmse:2616.34\teval-rmse:2651.78\n",
      "[300]\ttrain-rmse:2612.78\teval-rmse:2649.16\n",
      "[310]\ttrain-rmse:2609.54\teval-rmse:2646.82\n",
      "[320]\ttrain-rmse:2605.24\teval-rmse:2643.57\n",
      "[330]\ttrain-rmse:2601.75\teval-rmse:2640.89\n",
      "[340]\ttrain-rmse:2598.01\teval-rmse:2638.2\n",
      "[350]\ttrain-rmse:2594.8\teval-rmse:2635.86\n",
      "[360]\ttrain-rmse:2591.65\teval-rmse:2633.65\n",
      "[370]\ttrain-rmse:2588.48\teval-rmse:2631.38\n",
      "[380]\ttrain-rmse:2585.81\teval-rmse:2629.68\n",
      "[390]\ttrain-rmse:2582.62\teval-rmse:2627.41\n",
      "[400]\ttrain-rmse:2580.11\teval-rmse:2625.75\n",
      "[410]\ttrain-rmse:2577.4\teval-rmse:2623.85\n",
      "[420]\ttrain-rmse:2574.85\teval-rmse:2622.23\n",
      "[430]\ttrain-rmse:2571.96\teval-rmse:2620.2\n",
      "[440]\ttrain-rmse:2569.24\teval-rmse:2618.38\n",
      "[450]\ttrain-rmse:2566.95\teval-rmse:2616.9\n",
      "[460]\ttrain-rmse:2564.42\teval-rmse:2615.22\n",
      "[470]\ttrain-rmse:2562.06\teval-rmse:2613.68\n",
      "[480]\ttrain-rmse:2559.93\teval-rmse:2612.51\n",
      "[490]\ttrain-rmse:2557.32\teval-rmse:2610.93\n",
      "[500]\ttrain-rmse:2554.71\teval-rmse:2609.18\n",
      "[510]\ttrain-rmse:2551.77\teval-rmse:2607.13\n",
      "[520]\ttrain-rmse:2549.49\teval-rmse:2605.71\n",
      "[530]\ttrain-rmse:2546.58\teval-rmse:2603.6\n",
      "[540]\ttrain-rmse:2543.61\teval-rmse:2601.58\n",
      "[550]\ttrain-rmse:2540.96\teval-rmse:2599.9\n",
      "[560]\ttrain-rmse:2538.96\teval-rmse:2598.61\n",
      "[570]\ttrain-rmse:2536.27\teval-rmse:2596.8\n",
      "[580]\ttrain-rmse:2534.27\teval-rmse:2595.55\n",
      "[590]\ttrain-rmse:2532.3\teval-rmse:2594.52\n",
      "[600]\ttrain-rmse:2530.15\teval-rmse:2593.28\n",
      "[610]\ttrain-rmse:2528.25\teval-rmse:2592.28\n",
      "[620]\ttrain-rmse:2526.01\teval-rmse:2591\n",
      "[630]\ttrain-rmse:2524.14\teval-rmse:2590.05\n",
      "[640]\ttrain-rmse:2522.16\teval-rmse:2588.94\n",
      "[650]\ttrain-rmse:2519.77\teval-rmse:2587.41\n",
      "[660]\ttrain-rmse:2517.81\teval-rmse:2586.36\n",
      "[670]\ttrain-rmse:2515.5\teval-rmse:2584.94\n",
      "[680]\ttrain-rmse:2513.58\teval-rmse:2583.87\n",
      "[690]\ttrain-rmse:2510.92\teval-rmse:2582.29\n",
      "[700]\ttrain-rmse:2508.98\teval-rmse:2581.2\n",
      "[710]\ttrain-rmse:2507.22\teval-rmse:2580.3\n",
      "[720]\ttrain-rmse:2505.46\teval-rmse:2579.37\n",
      "[730]\ttrain-rmse:2503.28\teval-rmse:2577.87\n",
      "[740]\ttrain-rmse:2501.61\teval-rmse:2577.11\n",
      "[750]\ttrain-rmse:2499.09\teval-rmse:2575.45\n",
      "[760]\ttrain-rmse:2497.52\teval-rmse:2574.63\n",
      "[770]\ttrain-rmse:2495.72\teval-rmse:2573.56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[780]\ttrain-rmse:2493.99\teval-rmse:2572.71\n",
      "[790]\ttrain-rmse:2492.55\teval-rmse:2572.11\n",
      "[800]\ttrain-rmse:2490.94\teval-rmse:2571.22\n",
      "[810]\ttrain-rmse:2488.96\teval-rmse:2570.06\n",
      "[820]\ttrain-rmse:2487.01\teval-rmse:2568.9\n",
      "[830]\ttrain-rmse:2485.51\teval-rmse:2568.25\n",
      "[840]\ttrain-rmse:2483.94\teval-rmse:2567.5\n",
      "[850]\ttrain-rmse:2482.35\teval-rmse:2566.69\n",
      "[860]\ttrain-rmse:2480.94\teval-rmse:2566\n",
      "[870]\ttrain-rmse:2479.14\teval-rmse:2565.03\n",
      "[880]\ttrain-rmse:2477.77\teval-rmse:2564.43\n",
      "[890]\ttrain-rmse:2475.95\teval-rmse:2563.56\n",
      "[900]\ttrain-rmse:2473.76\teval-rmse:2562.19\n",
      "[910]\ttrain-rmse:2472.23\teval-rmse:2561.43\n",
      "[920]\ttrain-rmse:2471.06\teval-rmse:2560.98\n",
      "[930]\ttrain-rmse:2469.61\teval-rmse:2560.3\n",
      "[940]\ttrain-rmse:2468.22\teval-rmse:2559.68\n",
      "[950]\ttrain-rmse:2466.96\teval-rmse:2559.33\n",
      "[960]\ttrain-rmse:2465.43\teval-rmse:2558.56\n",
      "[970]\ttrain-rmse:2464.37\teval-rmse:2558.23\n",
      "[980]\ttrain-rmse:2462.68\teval-rmse:2557.45\n",
      "[990]\ttrain-rmse:2460.82\teval-rmse:2556.51\n",
      "[1000]\ttrain-rmse:2459.1\teval-rmse:2555.58\n",
      "[1010]\ttrain-rmse:2458.1\teval-rmse:2555.23\n",
      "[1020]\ttrain-rmse:2456.7\teval-rmse:2554.7\n",
      "[1030]\ttrain-rmse:2454.97\teval-rmse:2553.8\n",
      "[1040]\ttrain-rmse:2452.98\teval-rmse:2552.65\n",
      "[1050]\ttrain-rmse:2451.48\teval-rmse:2551.92\n",
      "[1060]\ttrain-rmse:2450.12\teval-rmse:2551.46\n",
      "[1070]\ttrain-rmse:2448.82\teval-rmse:2550.93\n",
      "[1080]\ttrain-rmse:2447.06\teval-rmse:2550.2\n",
      "[1090]\ttrain-rmse:2445.22\teval-rmse:2549.12\n",
      "[1100]\ttrain-rmse:2443.59\teval-rmse:2548.36\n",
      "[1110]\ttrain-rmse:2442.02\teval-rmse:2547.61\n",
      "[1120]\ttrain-rmse:2440.6\teval-rmse:2547.02\n",
      "[1130]\ttrain-rmse:2439.19\teval-rmse:2546.41\n",
      "[1140]\ttrain-rmse:2437.96\teval-rmse:2545.94\n",
      "[1150]\ttrain-rmse:2436.48\teval-rmse:2545.31\n",
      "[1160]\ttrain-rmse:2435.27\teval-rmse:2545.03\n",
      "[1170]\ttrain-rmse:2434.08\teval-rmse:2544.5\n",
      "[1180]\ttrain-rmse:2432.42\teval-rmse:2543.75\n",
      "[1190]\ttrain-rmse:2430.98\teval-rmse:2543.2\n",
      "[1200]\ttrain-rmse:2429.68\teval-rmse:2542.66\n",
      "[1210]\ttrain-rmse:2428.25\teval-rmse:2542.04\n",
      "[1220]\ttrain-rmse:2427\teval-rmse:2541.6\n",
      "[1230]\ttrain-rmse:2425.82\teval-rmse:2541.09\n",
      "[1240]\ttrain-rmse:2424.54\teval-rmse:2540.47\n",
      "[1250]\ttrain-rmse:2423.05\teval-rmse:2539.8\n",
      "[1260]\ttrain-rmse:2421.57\teval-rmse:2539.21\n",
      "[1270]\ttrain-rmse:2420.21\teval-rmse:2538.62\n",
      "[1280]\ttrain-rmse:2418.98\teval-rmse:2538.11\n",
      "[1290]\ttrain-rmse:2417.7\teval-rmse:2537.51\n",
      "[1300]\ttrain-rmse:2416.41\teval-rmse:2536.93\n",
      "[1310]\ttrain-rmse:2415.17\teval-rmse:2536.41\n",
      "[1320]\ttrain-rmse:2413.7\teval-rmse:2535.75\n",
      "[1330]\ttrain-rmse:2412.39\teval-rmse:2535.17\n",
      "[1340]\ttrain-rmse:2411.08\teval-rmse:2534.59\n",
      "[1350]\ttrain-rmse:2409.9\teval-rmse:2534.07\n",
      "[1360]\ttrain-rmse:2408.45\teval-rmse:2533.29\n",
      "[1370]\ttrain-rmse:2407.37\teval-rmse:2532.89\n",
      "[1380]\ttrain-rmse:2406.25\teval-rmse:2532.49\n",
      "[1390]\ttrain-rmse:2405.04\teval-rmse:2532\n",
      "[1400]\ttrain-rmse:2404\teval-rmse:2531.64\n",
      "[1410]\ttrain-rmse:2402.96\teval-rmse:2531.34\n",
      "[1420]\ttrain-rmse:2402.01\teval-rmse:2531.13\n",
      "[1430]\ttrain-rmse:2400.84\teval-rmse:2530.78\n",
      "[1440]\ttrain-rmse:2399.49\teval-rmse:2530.16\n",
      "[1450]\ttrain-rmse:2398.31\teval-rmse:2529.74\n",
      "[1460]\ttrain-rmse:2397.19\teval-rmse:2529.33\n",
      "[1470]\ttrain-rmse:2396.27\teval-rmse:2528.95\n",
      "[1480]\ttrain-rmse:2395.19\teval-rmse:2528.67\n",
      "[1490]\ttrain-rmse:2394.12\teval-rmse:2528.32\n",
      "[1500]\ttrain-rmse:2392.9\teval-rmse:2527.79\n",
      "[1510]\ttrain-rmse:2391.8\teval-rmse:2527.3\n",
      "[1520]\ttrain-rmse:2390.45\teval-rmse:2526.72\n",
      "[1530]\ttrain-rmse:2389.28\teval-rmse:2526.29\n",
      "[1540]\ttrain-rmse:2387.91\teval-rmse:2525.85\n",
      "[1550]\ttrain-rmse:2386.89\teval-rmse:2525.53\n",
      "[1560]\ttrain-rmse:2386.02\teval-rmse:2525.22\n",
      "[1570]\ttrain-rmse:2384.86\teval-rmse:2524.82\n",
      "[1580]\ttrain-rmse:2383.98\teval-rmse:2524.51\n",
      "[1590]\ttrain-rmse:2382.82\teval-rmse:2524.11\n",
      "[1600]\ttrain-rmse:2381.85\teval-rmse:2523.83\n",
      "[1610]\ttrain-rmse:2380.8\teval-rmse:2523.44\n",
      "[1620]\ttrain-rmse:2379.81\teval-rmse:2523.09\n",
      "[1630]\ttrain-rmse:2378.73\teval-rmse:2522.8\n",
      "[1640]\ttrain-rmse:2377.69\teval-rmse:2522.5\n",
      "[1650]\ttrain-rmse:2376.42\teval-rmse:2522.05\n",
      "[1660]\ttrain-rmse:2375.11\teval-rmse:2521.54\n",
      "[1670]\ttrain-rmse:2373.9\teval-rmse:2521.06\n",
      "[1680]\ttrain-rmse:2372.93\teval-rmse:2520.76\n",
      "[1690]\ttrain-rmse:2372.11\teval-rmse:2520.59\n",
      "[1700]\ttrain-rmse:2370.97\teval-rmse:2520.15\n",
      "[1710]\ttrain-rmse:2369.94\teval-rmse:2519.94\n",
      "[1720]\ttrain-rmse:2369.11\teval-rmse:2519.72\n",
      "[1730]\ttrain-rmse:2368.22\teval-rmse:2519.49\n",
      "[1740]\ttrain-rmse:2367.35\teval-rmse:2519.32\n",
      "[1750]\ttrain-rmse:2366.25\teval-rmse:2518.89\n",
      "[1760]\ttrain-rmse:2365.41\teval-rmse:2518.76\n",
      "[1770]\ttrain-rmse:2364.46\teval-rmse:2518.49\n",
      "[1780]\ttrain-rmse:2363.58\teval-rmse:2518.25\n",
      "[1790]\ttrain-rmse:2362.85\teval-rmse:2518.07\n",
      "[1800]\ttrain-rmse:2362.02\teval-rmse:2517.87\n",
      "[1810]\ttrain-rmse:2360.78\teval-rmse:2517.47\n",
      "[1820]\ttrain-rmse:2359.77\teval-rmse:2517.21\n",
      "[1830]\ttrain-rmse:2358.67\teval-rmse:2516.85\n",
      "[1840]\ttrain-rmse:2357.9\teval-rmse:2516.67\n",
      "[1850]\ttrain-rmse:2356.86\teval-rmse:2516.37\n",
      "[1860]\ttrain-rmse:2355.9\teval-rmse:2516.13\n",
      "[1870]\ttrain-rmse:2355.01\teval-rmse:2515.86\n",
      "[1880]\ttrain-rmse:2354\teval-rmse:2515.62\n",
      "[1890]\ttrain-rmse:2353.08\teval-rmse:2515.31\n",
      "[1900]\ttrain-rmse:2352.11\teval-rmse:2515.01\n",
      "[1910]\ttrain-rmse:2351.33\teval-rmse:2514.86\n",
      "[1920]\ttrain-rmse:2350.22\teval-rmse:2514.5\n",
      "[1930]\ttrain-rmse:2349.26\teval-rmse:2514.3\n",
      "[1940]\ttrain-rmse:2348.33\teval-rmse:2514.05\n",
      "[1950]\ttrain-rmse:2347.49\teval-rmse:2513.82\n",
      "[1960]\ttrain-rmse:2346.57\teval-rmse:2513.63\n",
      "[1970]\ttrain-rmse:2345.62\teval-rmse:2513.37\n",
      "[1980]\ttrain-rmse:2344.64\teval-rmse:2513.03\n",
      "[1990]\ttrain-rmse:2343.79\teval-rmse:2512.78\n",
      "[2000]\ttrain-rmse:2342.85\teval-rmse:2512.61\n",
      "[2010]\ttrain-rmse:2341.94\teval-rmse:2512.39\n",
      "[2020]\ttrain-rmse:2340.89\teval-rmse:2512.07\n",
      "[2030]\ttrain-rmse:2339.91\teval-rmse:2511.78\n",
      "[2040]\ttrain-rmse:2338.85\teval-rmse:2511.51\n",
      "[2050]\ttrain-rmse:2338.01\teval-rmse:2511.41\n",
      "[2060]\ttrain-rmse:2337.23\teval-rmse:2511.33\n",
      "[2070]\ttrain-rmse:2336.52\teval-rmse:2511.23\n",
      "[2080]\ttrain-rmse:2335.56\teval-rmse:2510.99\n",
      "[2090]\ttrain-rmse:2334.67\teval-rmse:2510.84\n",
      "[2100]\ttrain-rmse:2333.63\teval-rmse:2510.61\n",
      "[2110]\ttrain-rmse:2332.82\teval-rmse:2510.49\n",
      "[2120]\ttrain-rmse:2331.86\teval-rmse:2510.27\n",
      "[2130]\ttrain-rmse:2330.98\teval-rmse:2510.04\n",
      "[2140]\ttrain-rmse:2329.9\teval-rmse:2509.73\n",
      "[2150]\ttrain-rmse:2329.01\teval-rmse:2509.55\n",
      "[2160]\ttrain-rmse:2328.3\teval-rmse:2509.37\n",
      "[2170]\ttrain-rmse:2327.46\teval-rmse:2509.16\n",
      "[2180]\ttrain-rmse:2326.35\teval-rmse:2508.77\n",
      "[2190]\ttrain-rmse:2325.43\teval-rmse:2508.48\n",
      "[2200]\ttrain-rmse:2324.55\teval-rmse:2508.25\n",
      "[2210]\ttrain-rmse:2323.67\teval-rmse:2508.01\n",
      "[2220]\ttrain-rmse:2322.65\teval-rmse:2507.82\n",
      "[2230]\ttrain-rmse:2321.9\teval-rmse:2507.66\n",
      "[2240]\ttrain-rmse:2321.09\teval-rmse:2507.48\n",
      "[2250]\ttrain-rmse:2320.34\teval-rmse:2507.4\n",
      "[2260]\ttrain-rmse:2319.43\teval-rmse:2507.17\n",
      "[2270]\ttrain-rmse:2318.6\teval-rmse:2506.99\n",
      "[2280]\ttrain-rmse:2317.62\teval-rmse:2506.75\n",
      "[2290]\ttrain-rmse:2316.85\teval-rmse:2506.56\n",
      "[2300]\ttrain-rmse:2315.69\teval-rmse:2506.09\n",
      "[2310]\ttrain-rmse:2314.58\teval-rmse:2505.73\n",
      "[2320]\ttrain-rmse:2313.62\teval-rmse:2505.5\n",
      "[2330]\ttrain-rmse:2312.61\teval-rmse:2505.24\n",
      "[2340]\ttrain-rmse:2311.89\teval-rmse:2505.06\n",
      "[2350]\ttrain-rmse:2311.24\teval-rmse:2504.96\n",
      "[2360]\ttrain-rmse:2310.41\teval-rmse:2504.78\n",
      "[2370]\ttrain-rmse:2309.67\teval-rmse:2504.69\n",
      "[2380]\ttrain-rmse:2308.88\teval-rmse:2504.59\n",
      "[2390]\ttrain-rmse:2308.04\teval-rmse:2504.47\n",
      "[2400]\ttrain-rmse:2307.19\teval-rmse:2504.29\n",
      "[2410]\ttrain-rmse:2306.5\teval-rmse:2504.17\n",
      "[2420]\ttrain-rmse:2305.74\teval-rmse:2504.1\n",
      "[2430]\ttrain-rmse:2305\teval-rmse:2504.02\n",
      "[2440]\ttrain-rmse:2304.31\teval-rmse:2503.92\n",
      "[2450]\ttrain-rmse:2303.36\teval-rmse:2503.71\n",
      "[2460]\ttrain-rmse:2302.61\teval-rmse:2503.59\n",
      "[2470]\ttrain-rmse:2301.71\teval-rmse:2503.39\n",
      "[2480]\ttrain-rmse:2301\teval-rmse:2503.38\n",
      "[2490]\ttrain-rmse:2300.26\teval-rmse:2503.27\n",
      "[2500]\ttrain-rmse:2299.61\teval-rmse:2503.2\n",
      "[2510]\ttrain-rmse:2298.62\teval-rmse:2502.96\n",
      "[2520]\ttrain-rmse:2297.73\teval-rmse:2502.77\n",
      "[2530]\ttrain-rmse:2296.9\teval-rmse:2502.6\n",
      "[2540]\ttrain-rmse:2295.84\teval-rmse:2502.22\n",
      "[2550]\ttrain-rmse:2295.11\teval-rmse:2502.09\n",
      "[2560]\ttrain-rmse:2294.32\teval-rmse:2501.93\n",
      "[2570]\ttrain-rmse:2293.6\teval-rmse:2501.77\n",
      "[2580]\ttrain-rmse:2292.78\teval-rmse:2501.69\n",
      "[2590]\ttrain-rmse:2291.95\teval-rmse:2501.56\n",
      "[2600]\ttrain-rmse:2291.14\teval-rmse:2501.43\n",
      "[2610]\ttrain-rmse:2290.32\teval-rmse:2501.38\n",
      "[2620]\ttrain-rmse:2289.42\teval-rmse:2501.24\n",
      "[2630]\ttrain-rmse:2288.56\teval-rmse:2501.04\n",
      "[2640]\ttrain-rmse:2287.69\teval-rmse:2500.84\n",
      "[2650]\ttrain-rmse:2286.96\teval-rmse:2500.7\n",
      "[2660]\ttrain-rmse:2286.11\teval-rmse:2500.49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2670]\ttrain-rmse:2285.39\teval-rmse:2500.26\n",
      "[2680]\ttrain-rmse:2284.59\teval-rmse:2500.14\n",
      "[2690]\ttrain-rmse:2283.96\teval-rmse:2500.11\n",
      "[2700]\ttrain-rmse:2283.13\teval-rmse:2499.92\n",
      "[2710]\ttrain-rmse:2282.38\teval-rmse:2499.81\n",
      "[2720]\ttrain-rmse:2281.52\teval-rmse:2499.65\n",
      "[2730]\ttrain-rmse:2280.8\teval-rmse:2499.56\n",
      "[2740]\ttrain-rmse:2279.98\teval-rmse:2499.37\n",
      "[2750]\ttrain-rmse:2279.24\teval-rmse:2499.23\n",
      "[2760]\ttrain-rmse:2278.63\teval-rmse:2499.17\n",
      "[2770]\ttrain-rmse:2277.64\teval-rmse:2498.96\n",
      "[2780]\ttrain-rmse:2276.78\teval-rmse:2498.77\n",
      "[2790]\ttrain-rmse:2276.04\teval-rmse:2498.67\n",
      "[2800]\ttrain-rmse:2275.21\teval-rmse:2498.53\n",
      "[2810]\ttrain-rmse:2274.45\teval-rmse:2498.44\n",
      "[2820]\ttrain-rmse:2273.49\teval-rmse:2498.27\n",
      "[2830]\ttrain-rmse:2272.85\teval-rmse:2498.22\n",
      "[2840]\ttrain-rmse:2271.9\teval-rmse:2498.05\n",
      "[2850]\ttrain-rmse:2271.23\teval-rmse:2497.95\n",
      "[2860]\ttrain-rmse:2270.66\teval-rmse:2497.86\n",
      "[2870]\ttrain-rmse:2269.81\teval-rmse:2497.64\n",
      "[2880]\ttrain-rmse:2269.12\teval-rmse:2497.56\n",
      "[2890]\ttrain-rmse:2268.31\teval-rmse:2497.38\n",
      "[2900]\ttrain-rmse:2267.44\teval-rmse:2497.25\n",
      "[2910]\ttrain-rmse:2266.65\teval-rmse:2497.14\n",
      "[2920]\ttrain-rmse:2265.96\teval-rmse:2497.09\n",
      "[2930]\ttrain-rmse:2265.14\teval-rmse:2496.88\n",
      "[2940]\ttrain-rmse:2264.47\teval-rmse:2496.88\n",
      "[2950]\ttrain-rmse:2263.64\teval-rmse:2496.72\n",
      "[2960]\ttrain-rmse:2262.84\teval-rmse:2496.59\n",
      "[2970]\ttrain-rmse:2262.15\teval-rmse:2496.44\n",
      "[2980]\ttrain-rmse:2261.42\teval-rmse:2496.39\n",
      "[2990]\ttrain-rmse:2260.92\teval-rmse:2496.34\n",
      "[3000]\ttrain-rmse:2260.5\teval-rmse:2496.33\n",
      "[3010]\ttrain-rmse:2259.79\teval-rmse:2496.3\n",
      "[3020]\ttrain-rmse:2259.13\teval-rmse:2496.2\n",
      "[3030]\ttrain-rmse:2258.61\teval-rmse:2496.19\n",
      "[3040]\ttrain-rmse:2257.99\teval-rmse:2496.14\n",
      "[3050]\ttrain-rmse:2257.38\teval-rmse:2496.1\n",
      "[3060]\ttrain-rmse:2256.59\teval-rmse:2495.99\n",
      "[3070]\ttrain-rmse:2255.83\teval-rmse:2495.9\n",
      "[3080]\ttrain-rmse:2255.03\teval-rmse:2495.75\n",
      "[3090]\ttrain-rmse:2254.28\teval-rmse:2495.59\n",
      "[3100]\ttrain-rmse:2253.48\teval-rmse:2495.51\n",
      "[3110]\ttrain-rmse:2252.68\teval-rmse:2495.4\n",
      "[3120]\ttrain-rmse:2252.02\teval-rmse:2495.34\n",
      "[3130]\ttrain-rmse:2251.18\teval-rmse:2495.24\n",
      "[3140]\ttrain-rmse:2250.38\teval-rmse:2495.15\n",
      "[3150]\ttrain-rmse:2249.71\teval-rmse:2495.08\n",
      "[3160]\ttrain-rmse:2248.96\teval-rmse:2494.97\n",
      "[3170]\ttrain-rmse:2248.24\teval-rmse:2494.87\n",
      "[3180]\ttrain-rmse:2247.52\teval-rmse:2494.71\n",
      "[3190]\ttrain-rmse:2246.84\teval-rmse:2494.61\n",
      "[3200]\ttrain-rmse:2246.07\teval-rmse:2494.48\n",
      "[3210]\ttrain-rmse:2245.45\teval-rmse:2494.44\n",
      "[3220]\ttrain-rmse:2244.71\teval-rmse:2494.35\n",
      "[3230]\ttrain-rmse:2243.98\teval-rmse:2494.3\n",
      "[3240]\ttrain-rmse:2243.48\teval-rmse:2494.26\n",
      "[3250]\ttrain-rmse:2242.74\teval-rmse:2494.14\n",
      "[3260]\ttrain-rmse:2241.78\teval-rmse:2493.96\n",
      "[3270]\ttrain-rmse:2241.02\teval-rmse:2493.83\n",
      "[3280]\ttrain-rmse:2240.3\teval-rmse:2493.8\n",
      "[3290]\ttrain-rmse:2239.63\teval-rmse:2493.73\n",
      "[3300]\ttrain-rmse:2239.05\teval-rmse:2493.7\n",
      "[3310]\ttrain-rmse:2238.31\teval-rmse:2493.62\n",
      "[3320]\ttrain-rmse:2237.5\teval-rmse:2493.51\n",
      "[3330]\ttrain-rmse:2236.86\teval-rmse:2493.46\n",
      "[3340]\ttrain-rmse:2236.12\teval-rmse:2493.39\n",
      "[3350]\ttrain-rmse:2235.43\teval-rmse:2493.25\n",
      "[3360]\ttrain-rmse:2234.8\teval-rmse:2493.16\n",
      "[3370]\ttrain-rmse:2234.03\teval-rmse:2493.04\n",
      "[3380]\ttrain-rmse:2233.18\teval-rmse:2492.89\n",
      "[3390]\ttrain-rmse:2232.56\teval-rmse:2492.9\n",
      "Stopping. Best iteration:\n",
      "[3388]\ttrain-rmse:2232.7\teval-rmse:2492.88\n",
      "\n",
      "train_rmse :2232.696732660152\t test_score:2492.8776744604706\n",
      "[0]\ttrain-rmse:10067.7\teval-rmse:10049.9\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 10 rounds.\n",
      "[10]\ttrain-rmse:6465.39\teval-rmse:6452.02\n",
      "[20]\ttrain-rmse:4484.6\teval-rmse:4475.36\n",
      "[30]\ttrain-rmse:3500.36\teval-rmse:3494.77\n",
      "[40]\ttrain-rmse:3060.52\teval-rmse:3057.68\n",
      "[50]\ttrain-rmse:2877.65\teval-rmse:2877.29\n",
      "[60]\ttrain-rmse:2800.88\teval-rmse:2802.5\n",
      "[70]\ttrain-rmse:2763.31\teval-rmse:2766.31\n",
      "[80]\ttrain-rmse:2743.95\teval-rmse:2748.19\n",
      "[90]\ttrain-rmse:2730.43\teval-rmse:2735.96\n",
      "[100]\ttrain-rmse:2719.25\teval-rmse:2725.85\n",
      "[110]\ttrain-rmse:2711.53\teval-rmse:2719.04\n",
      "[120]\ttrain-rmse:2706.04\teval-rmse:2714.58\n",
      "[130]\ttrain-rmse:2698.93\teval-rmse:2708.36\n",
      "[140]\ttrain-rmse:2692.86\teval-rmse:2703.29\n",
      "[150]\ttrain-rmse:2686.4\teval-rmse:2697.86\n",
      "[160]\ttrain-rmse:2681.73\teval-rmse:2694.18\n",
      "[170]\ttrain-rmse:2674.79\teval-rmse:2688.28\n",
      "[180]\ttrain-rmse:2669.49\teval-rmse:2683.99\n",
      "[190]\ttrain-rmse:2663\teval-rmse:2678.49\n",
      "[200]\ttrain-rmse:2658.54\teval-rmse:2675.2\n",
      "[210]\ttrain-rmse:2653.04\teval-rmse:2670.69\n",
      "[220]\ttrain-rmse:2649.29\teval-rmse:2667.88\n",
      "[230]\ttrain-rmse:2644.59\teval-rmse:2664.27\n",
      "[240]\ttrain-rmse:2639.47\teval-rmse:2660.06\n",
      "[250]\ttrain-rmse:2635.75\teval-rmse:2657.26\n",
      "[260]\ttrain-rmse:2632.21\teval-rmse:2654.64\n",
      "[270]\ttrain-rmse:2629.01\teval-rmse:2652.23\n",
      "[280]\ttrain-rmse:2625.43\teval-rmse:2649.6\n",
      "[290]\ttrain-rmse:2621.3\teval-rmse:2646.34\n",
      "[300]\ttrain-rmse:2617.77\teval-rmse:2643.7\n",
      "[310]\ttrain-rmse:2613.96\teval-rmse:2640.77\n",
      "[320]\ttrain-rmse:2610.65\teval-rmse:2638.47\n",
      "[330]\ttrain-rmse:2606.28\teval-rmse:2635.13\n",
      "[340]\ttrain-rmse:2603.19\teval-rmse:2632.99\n",
      "[350]\ttrain-rmse:2599.64\teval-rmse:2630.44\n",
      "[360]\ttrain-rmse:2596.41\teval-rmse:2628.23\n",
      "[370]\ttrain-rmse:2593.55\teval-rmse:2626.41\n",
      "[380]\ttrain-rmse:2590.39\teval-rmse:2624.19\n",
      "[390]\ttrain-rmse:2587.46\teval-rmse:2622.35\n",
      "[400]\ttrain-rmse:2583.84\teval-rmse:2619.64\n",
      "[410]\ttrain-rmse:2581.08\teval-rmse:2617.91\n",
      "[420]\ttrain-rmse:2576.93\teval-rmse:2614.78\n",
      "[430]\ttrain-rmse:2573.41\teval-rmse:2612.12\n",
      "[440]\ttrain-rmse:2569.74\teval-rmse:2609.41\n",
      "[450]\ttrain-rmse:2567.27\teval-rmse:2607.82\n",
      "[460]\ttrain-rmse:2564.39\teval-rmse:2605.99\n",
      "[470]\ttrain-rmse:2561.99\teval-rmse:2604.45\n",
      "[480]\ttrain-rmse:2559.63\teval-rmse:2602.97\n",
      "[490]\ttrain-rmse:2557.61\teval-rmse:2601.95\n",
      "[500]\ttrain-rmse:2554.71\teval-rmse:2599.88\n",
      "[510]\ttrain-rmse:2552.01\teval-rmse:2598.13\n",
      "[520]\ttrain-rmse:2549.63\teval-rmse:2596.65\n",
      "[530]\ttrain-rmse:2547.44\teval-rmse:2595.25\n",
      "[540]\ttrain-rmse:2545.3\teval-rmse:2593.91\n",
      "[550]\ttrain-rmse:2543.35\teval-rmse:2592.84\n",
      "[560]\ttrain-rmse:2541.49\teval-rmse:2591.9\n",
      "[570]\ttrain-rmse:2539.3\teval-rmse:2590.59\n",
      "[580]\ttrain-rmse:2536.95\teval-rmse:2589.01\n",
      "[590]\ttrain-rmse:2534.8\teval-rmse:2587.78\n",
      "[600]\ttrain-rmse:2532.64\teval-rmse:2586.7\n",
      "[610]\ttrain-rmse:2530.46\teval-rmse:2585.44\n",
      "[620]\ttrain-rmse:2527.71\teval-rmse:2583.64\n",
      "[630]\ttrain-rmse:2525.26\teval-rmse:2582.19\n",
      "[640]\ttrain-rmse:2523.28\teval-rmse:2581.11\n",
      "[650]\ttrain-rmse:2521.38\teval-rmse:2580.01\n",
      "[660]\ttrain-rmse:2519.66\teval-rmse:2579.09\n",
      "[670]\ttrain-rmse:2517.74\teval-rmse:2578.02\n",
      "[680]\ttrain-rmse:2515.84\teval-rmse:2577.04\n",
      "[690]\ttrain-rmse:2514.09\teval-rmse:2576.14\n",
      "[700]\ttrain-rmse:2512.17\teval-rmse:2575.11\n",
      "[710]\ttrain-rmse:2510.57\teval-rmse:2574.32\n",
      "[720]\ttrain-rmse:2508.62\teval-rmse:2573.15\n",
      "[730]\ttrain-rmse:2506.48\teval-rmse:2571.98\n",
      "[740]\ttrain-rmse:2505.05\teval-rmse:2571.34\n",
      "[750]\ttrain-rmse:2503.36\teval-rmse:2570.45\n",
      "[760]\ttrain-rmse:2501.12\teval-rmse:2569.13\n",
      "[770]\ttrain-rmse:2499.13\teval-rmse:2568.03\n",
      "[780]\ttrain-rmse:2497.31\teval-rmse:2567.02\n",
      "[790]\ttrain-rmse:2495\teval-rmse:2565.71\n",
      "[800]\ttrain-rmse:2493.15\teval-rmse:2564.76\n",
      "[810]\ttrain-rmse:2491.31\teval-rmse:2563.7\n",
      "[820]\ttrain-rmse:2489.99\teval-rmse:2563.12\n",
      "[830]\ttrain-rmse:2487.86\teval-rmse:2561.79\n",
      "[840]\ttrain-rmse:2486.05\teval-rmse:2560.73\n",
      "[850]\ttrain-rmse:2484.15\teval-rmse:2559.68\n",
      "[860]\ttrain-rmse:2482.94\teval-rmse:2559.18\n",
      "[870]\ttrain-rmse:2481.16\teval-rmse:2558.14\n",
      "[880]\ttrain-rmse:2479.88\teval-rmse:2557.63\n",
      "[890]\ttrain-rmse:2477.85\teval-rmse:2556.52\n",
      "[900]\ttrain-rmse:2475.81\teval-rmse:2555.25\n",
      "[910]\ttrain-rmse:2473.78\teval-rmse:2554.11\n",
      "[920]\ttrain-rmse:2471.99\teval-rmse:2553.33\n",
      "[930]\ttrain-rmse:2470.04\teval-rmse:2552.26\n",
      "[940]\ttrain-rmse:2468.21\teval-rmse:2551.34\n",
      "[950]\ttrain-rmse:2466.96\teval-rmse:2550.7\n",
      "[960]\ttrain-rmse:2465.2\teval-rmse:2549.86\n",
      "[970]\ttrain-rmse:2463.36\teval-rmse:2549.03\n",
      "[980]\ttrain-rmse:2461.94\teval-rmse:2548.4\n",
      "[990]\ttrain-rmse:2460.42\teval-rmse:2547.64\n",
      "[1000]\ttrain-rmse:2458.72\teval-rmse:2546.85\n",
      "[1010]\ttrain-rmse:2457.2\teval-rmse:2546.24\n",
      "[1020]\ttrain-rmse:2455.51\teval-rmse:2545.42\n",
      "[1030]\ttrain-rmse:2454.15\teval-rmse:2544.84\n",
      "[1040]\ttrain-rmse:2452.8\teval-rmse:2544.25\n",
      "[1050]\ttrain-rmse:2451.1\teval-rmse:2543.33\n",
      "[1060]\ttrain-rmse:2449.57\teval-rmse:2542.66\n",
      "[1070]\ttrain-rmse:2448.12\teval-rmse:2542.03\n",
      "[1080]\ttrain-rmse:2446.78\teval-rmse:2541.38\n",
      "[1090]\ttrain-rmse:2445.33\teval-rmse:2540.78\n",
      "[1100]\ttrain-rmse:2443.7\teval-rmse:2539.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1110]\ttrain-rmse:2442.3\teval-rmse:2539.24\n",
      "[1120]\ttrain-rmse:2441.03\teval-rmse:2538.68\n",
      "[1130]\ttrain-rmse:2439.77\teval-rmse:2538.19\n",
      "[1140]\ttrain-rmse:2438.38\teval-rmse:2537.59\n",
      "[1150]\ttrain-rmse:2436.87\teval-rmse:2536.88\n",
      "[1160]\ttrain-rmse:2435.52\teval-rmse:2536.35\n",
      "[1170]\ttrain-rmse:2434.28\teval-rmse:2535.88\n",
      "[1180]\ttrain-rmse:2433.12\teval-rmse:2535.36\n",
      "[1190]\ttrain-rmse:2431.85\teval-rmse:2534.94\n",
      "[1200]\ttrain-rmse:2430.4\teval-rmse:2534.3\n",
      "[1210]\ttrain-rmse:2428.88\teval-rmse:2533.76\n",
      "[1220]\ttrain-rmse:2427.51\teval-rmse:2533.05\n",
      "[1230]\ttrain-rmse:2426.34\teval-rmse:2532.65\n",
      "[1240]\ttrain-rmse:2424.95\teval-rmse:2532.05\n",
      "[1250]\ttrain-rmse:2423.37\teval-rmse:2531.29\n",
      "[1260]\ttrain-rmse:2422.13\teval-rmse:2530.84\n",
      "[1270]\ttrain-rmse:2420.94\teval-rmse:2530.33\n",
      "[1280]\ttrain-rmse:2419.92\teval-rmse:2529.94\n",
      "[1290]\ttrain-rmse:2419.02\teval-rmse:2529.6\n",
      "[1300]\ttrain-rmse:2417.74\teval-rmse:2529.12\n",
      "[1310]\ttrain-rmse:2416.46\teval-rmse:2528.61\n",
      "[1320]\ttrain-rmse:2415.5\teval-rmse:2528.27\n",
      "[1330]\ttrain-rmse:2414.17\teval-rmse:2527.67\n",
      "[1340]\ttrain-rmse:2413.06\teval-rmse:2527.33\n",
      "[1350]\ttrain-rmse:2411.76\teval-rmse:2526.82\n",
      "[1360]\ttrain-rmse:2410.75\teval-rmse:2526.41\n",
      "[1370]\ttrain-rmse:2409.71\teval-rmse:2526.14\n",
      "[1380]\ttrain-rmse:2408.54\teval-rmse:2525.71\n",
      "[1390]\ttrain-rmse:2407.2\teval-rmse:2525.13\n",
      "[1400]\ttrain-rmse:2405.92\teval-rmse:2524.77\n",
      "[1410]\ttrain-rmse:2404.39\teval-rmse:2524.11\n",
      "[1420]\ttrain-rmse:2402.97\teval-rmse:2523.45\n",
      "[1430]\ttrain-rmse:2401.82\teval-rmse:2523.06\n",
      "[1440]\ttrain-rmse:2400.65\teval-rmse:2522.73\n",
      "[1450]\ttrain-rmse:2399.51\teval-rmse:2522.45\n",
      "[1460]\ttrain-rmse:2398.36\teval-rmse:2522.21\n",
      "[1470]\ttrain-rmse:2396.75\teval-rmse:2521.48\n",
      "[1480]\ttrain-rmse:2395.42\teval-rmse:2521.01\n",
      "[1490]\ttrain-rmse:2394.13\teval-rmse:2520.63\n",
      "[1500]\ttrain-rmse:2393.16\teval-rmse:2520.28\n",
      "[1510]\ttrain-rmse:2392\teval-rmse:2519.85\n",
      "[1520]\ttrain-rmse:2390.59\teval-rmse:2519.33\n",
      "[1530]\ttrain-rmse:2389.41\teval-rmse:2518.83\n",
      "[1540]\ttrain-rmse:2388.17\teval-rmse:2518.41\n",
      "[1550]\ttrain-rmse:2387.1\teval-rmse:2518.12\n",
      "[1560]\ttrain-rmse:2385.84\teval-rmse:2517.82\n",
      "[1570]\ttrain-rmse:2384.76\teval-rmse:2517.37\n",
      "[1580]\ttrain-rmse:2383.48\teval-rmse:2517.07\n",
      "[1590]\ttrain-rmse:2382.33\teval-rmse:2516.75\n",
      "[1600]\ttrain-rmse:2381.19\teval-rmse:2516.36\n",
      "[1610]\ttrain-rmse:2380.28\teval-rmse:2516.11\n",
      "[1620]\ttrain-rmse:2379.02\teval-rmse:2515.63\n",
      "[1630]\ttrain-rmse:2377.96\teval-rmse:2515.34\n",
      "[1640]\ttrain-rmse:2376.58\teval-rmse:2514.87\n",
      "[1650]\ttrain-rmse:2375.36\teval-rmse:2514.43\n",
      "[1660]\ttrain-rmse:2374.4\teval-rmse:2514.07\n",
      "[1670]\ttrain-rmse:2373.31\teval-rmse:2513.7\n",
      "[1680]\ttrain-rmse:2372.3\teval-rmse:2513.44\n",
      "[1690]\ttrain-rmse:2370.97\teval-rmse:2512.97\n",
      "[1700]\ttrain-rmse:2369.84\teval-rmse:2512.76\n",
      "[1710]\ttrain-rmse:2368.67\teval-rmse:2512.4\n",
      "[1720]\ttrain-rmse:2367.47\teval-rmse:2512.05\n",
      "[1730]\ttrain-rmse:2366.54\teval-rmse:2511.79\n",
      "[1740]\ttrain-rmse:2365.51\teval-rmse:2511.56\n",
      "[1750]\ttrain-rmse:2364.49\teval-rmse:2511.31\n",
      "[1760]\ttrain-rmse:2363.55\teval-rmse:2511.11\n",
      "[1770]\ttrain-rmse:2362.65\teval-rmse:2510.99\n",
      "[1780]\ttrain-rmse:2361.81\teval-rmse:2510.86\n",
      "[1790]\ttrain-rmse:2360.77\teval-rmse:2510.59\n",
      "[1800]\ttrain-rmse:2359.7\teval-rmse:2510.36\n",
      "[1810]\ttrain-rmse:2358.74\teval-rmse:2510.11\n",
      "[1820]\ttrain-rmse:2357.67\teval-rmse:2509.81\n",
      "[1830]\ttrain-rmse:2356.65\teval-rmse:2509.5\n",
      "[1840]\ttrain-rmse:2355.68\teval-rmse:2509.25\n",
      "[1850]\ttrain-rmse:2354.7\teval-rmse:2509.05\n",
      "[1860]\ttrain-rmse:2353.64\teval-rmse:2508.81\n",
      "[1870]\ttrain-rmse:2352.52\teval-rmse:2508.47\n",
      "[1880]\ttrain-rmse:2351.52\teval-rmse:2508.22\n",
      "[1890]\ttrain-rmse:2350.5\teval-rmse:2507.95\n",
      "[1900]\ttrain-rmse:2349.43\teval-rmse:2507.62\n",
      "[1910]\ttrain-rmse:2348.4\teval-rmse:2507.27\n",
      "[1920]\ttrain-rmse:2347.48\teval-rmse:2507.02\n",
      "[1930]\ttrain-rmse:2346.66\teval-rmse:2506.84\n",
      "[1940]\ttrain-rmse:2345.81\teval-rmse:2506.69\n",
      "[1950]\ttrain-rmse:2345.13\teval-rmse:2506.61\n",
      "[1960]\ttrain-rmse:2344.36\teval-rmse:2506.49\n",
      "[1970]\ttrain-rmse:2343.25\teval-rmse:2506.24\n",
      "[1980]\ttrain-rmse:2342.05\teval-rmse:2505.97\n",
      "[1990]\ttrain-rmse:2340.99\teval-rmse:2505.7\n",
      "[2000]\ttrain-rmse:2339.95\teval-rmse:2505.42\n",
      "[2010]\ttrain-rmse:2339.18\teval-rmse:2505.16\n",
      "[2020]\ttrain-rmse:2338.36\teval-rmse:2504.97\n",
      "[2030]\ttrain-rmse:2337.38\teval-rmse:2504.67\n",
      "[2040]\ttrain-rmse:2336.53\teval-rmse:2504.4\n",
      "[2050]\ttrain-rmse:2335.73\teval-rmse:2504.2\n",
      "[2060]\ttrain-rmse:2334.95\teval-rmse:2504\n",
      "[2070]\ttrain-rmse:2334.12\teval-rmse:2503.82\n",
      "[2080]\ttrain-rmse:2333.31\teval-rmse:2503.68\n",
      "[2090]\ttrain-rmse:2332.36\teval-rmse:2503.46\n",
      "[2100]\ttrain-rmse:2331.25\teval-rmse:2503.12\n",
      "[2110]\ttrain-rmse:2330.19\teval-rmse:2502.88\n",
      "[2120]\ttrain-rmse:2329.2\teval-rmse:2502.62\n",
      "[2130]\ttrain-rmse:2328.04\teval-rmse:2502.3\n",
      "[2140]\ttrain-rmse:2326.77\teval-rmse:2502\n",
      "[2150]\ttrain-rmse:2325.51\teval-rmse:2501.55\n",
      "[2160]\ttrain-rmse:2324.61\teval-rmse:2501.17\n",
      "[2170]\ttrain-rmse:2323.49\teval-rmse:2500.9\n",
      "[2180]\ttrain-rmse:2322.51\teval-rmse:2500.73\n",
      "[2190]\ttrain-rmse:2321.49\teval-rmse:2500.49\n",
      "[2200]\ttrain-rmse:2320.49\teval-rmse:2500.23\n",
      "[2210]\ttrain-rmse:2319.69\teval-rmse:2500.11\n",
      "[2220]\ttrain-rmse:2318.9\teval-rmse:2499.88\n",
      "[2230]\ttrain-rmse:2317.97\teval-rmse:2499.69\n",
      "[2240]\ttrain-rmse:2317.12\teval-rmse:2499.52\n",
      "[2250]\ttrain-rmse:2316.22\teval-rmse:2499.27\n",
      "[2260]\ttrain-rmse:2315.59\teval-rmse:2499.2\n",
      "[2270]\ttrain-rmse:2314.82\teval-rmse:2499.14\n",
      "[2280]\ttrain-rmse:2314.17\teval-rmse:2499.12\n",
      "[2290]\ttrain-rmse:2313.21\teval-rmse:2498.86\n",
      "[2300]\ttrain-rmse:2312.37\teval-rmse:2498.73\n",
      "[2310]\ttrain-rmse:2311.45\teval-rmse:2498.45\n",
      "[2320]\ttrain-rmse:2310.71\teval-rmse:2498.22\n",
      "[2330]\ttrain-rmse:2309.89\teval-rmse:2498.01\n",
      "[2340]\ttrain-rmse:2309.08\teval-rmse:2497.83\n",
      "[2350]\ttrain-rmse:2308.02\teval-rmse:2497.59\n",
      "[2360]\ttrain-rmse:2307.41\teval-rmse:2497.55\n",
      "[2370]\ttrain-rmse:2306.56\teval-rmse:2497.39\n",
      "[2380]\ttrain-rmse:2305.6\teval-rmse:2497.15\n",
      "[2390]\ttrain-rmse:2304.94\teval-rmse:2497.04\n",
      "[2400]\ttrain-rmse:2304.34\teval-rmse:2496.98\n",
      "[2410]\ttrain-rmse:2303.64\teval-rmse:2496.9\n",
      "[2420]\ttrain-rmse:2302.79\teval-rmse:2496.67\n",
      "[2430]\ttrain-rmse:2301.91\teval-rmse:2496.49\n",
      "[2440]\ttrain-rmse:2301.14\teval-rmse:2496.33\n",
      "[2450]\ttrain-rmse:2300.35\teval-rmse:2496.17\n",
      "[2460]\ttrain-rmse:2299.46\teval-rmse:2495.98\n",
      "[2470]\ttrain-rmse:2298.9\teval-rmse:2495.87\n",
      "[2480]\ttrain-rmse:2298.18\teval-rmse:2495.8\n",
      "[2490]\ttrain-rmse:2297.34\teval-rmse:2495.54\n",
      "[2500]\ttrain-rmse:2296.45\teval-rmse:2495.36\n",
      "[2510]\ttrain-rmse:2295.6\teval-rmse:2495.22\n",
      "[2520]\ttrain-rmse:2294.65\teval-rmse:2495\n",
      "[2530]\ttrain-rmse:2293.96\teval-rmse:2494.85\n",
      "[2540]\ttrain-rmse:2293.33\teval-rmse:2494.76\n",
      "[2550]\ttrain-rmse:2292.46\teval-rmse:2494.62\n",
      "[2560]\ttrain-rmse:2291.7\teval-rmse:2494.53\n",
      "[2570]\ttrain-rmse:2291\teval-rmse:2494.45\n",
      "[2580]\ttrain-rmse:2290.12\teval-rmse:2494.28\n",
      "[2590]\ttrain-rmse:2289.44\teval-rmse:2494.17\n",
      "[2600]\ttrain-rmse:2288.67\teval-rmse:2494.06\n",
      "[2610]\ttrain-rmse:2287.75\teval-rmse:2493.93\n",
      "[2620]\ttrain-rmse:2286.99\teval-rmse:2493.74\n",
      "[2630]\ttrain-rmse:2286.13\teval-rmse:2493.65\n",
      "[2640]\ttrain-rmse:2285.33\teval-rmse:2493.54\n",
      "[2650]\ttrain-rmse:2284.48\teval-rmse:2493.44\n",
      "[2660]\ttrain-rmse:2283.64\teval-rmse:2493.28\n",
      "[2670]\ttrain-rmse:2282.92\teval-rmse:2493.09\n",
      "[2680]\ttrain-rmse:2282.16\teval-rmse:2492.92\n",
      "[2690]\ttrain-rmse:2281.52\teval-rmse:2492.82\n",
      "[2700]\ttrain-rmse:2280.82\teval-rmse:2492.68\n",
      "[2710]\ttrain-rmse:2280\teval-rmse:2492.57\n",
      "[2720]\ttrain-rmse:2279.34\teval-rmse:2492.43\n",
      "[2730]\ttrain-rmse:2278.61\teval-rmse:2492.32\n",
      "[2740]\ttrain-rmse:2277.79\teval-rmse:2492.19\n",
      "[2750]\ttrain-rmse:2277.04\teval-rmse:2492.16\n",
      "[2760]\ttrain-rmse:2276.26\teval-rmse:2492.07\n",
      "[2770]\ttrain-rmse:2275.51\teval-rmse:2491.96\n",
      "[2780]\ttrain-rmse:2274.89\teval-rmse:2491.83\n",
      "[2790]\ttrain-rmse:2274.16\teval-rmse:2491.74\n",
      "[2800]\ttrain-rmse:2273.43\teval-rmse:2491.66\n",
      "[2810]\ttrain-rmse:2272.59\teval-rmse:2491.58\n",
      "[2820]\ttrain-rmse:2271.66\teval-rmse:2491.47\n",
      "[2830]\ttrain-rmse:2270.9\teval-rmse:2491.35\n",
      "[2840]\ttrain-rmse:2270.19\teval-rmse:2491.18\n",
      "[2850]\ttrain-rmse:2269.51\teval-rmse:2491.11\n",
      "[2860]\ttrain-rmse:2268.78\teval-rmse:2491.07\n",
      "[2870]\ttrain-rmse:2267.99\teval-rmse:2490.98\n",
      "[2880]\ttrain-rmse:2267.36\teval-rmse:2490.9\n",
      "[2890]\ttrain-rmse:2266.87\teval-rmse:2490.82\n",
      "[2900]\ttrain-rmse:2266.12\teval-rmse:2490.73\n",
      "[2910]\ttrain-rmse:2265.36\teval-rmse:2490.59\n",
      "[2920]\ttrain-rmse:2264.49\teval-rmse:2490.49\n",
      "[2930]\ttrain-rmse:2263.76\teval-rmse:2490.4\n",
      "[2940]\ttrain-rmse:2263.02\teval-rmse:2490.3\n",
      "[2950]\ttrain-rmse:2262.26\teval-rmse:2490.2\n",
      "[2960]\ttrain-rmse:2261.35\teval-rmse:2490.03\n",
      "[2970]\ttrain-rmse:2260.64\teval-rmse:2489.92\n",
      "[2980]\ttrain-rmse:2259.85\teval-rmse:2489.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2990]\ttrain-rmse:2259.08\teval-rmse:2489.77\n",
      "[3000]\ttrain-rmse:2258.27\teval-rmse:2489.67\n",
      "[3010]\ttrain-rmse:2257.53\teval-rmse:2489.56\n",
      "[3020]\ttrain-rmse:2256.72\teval-rmse:2489.47\n",
      "[3030]\ttrain-rmse:2255.96\teval-rmse:2489.42\n",
      "[3040]\ttrain-rmse:2255.04\teval-rmse:2489.26\n",
      "[3050]\ttrain-rmse:2254.21\teval-rmse:2489.09\n",
      "[3060]\ttrain-rmse:2253.53\teval-rmse:2489.02\n",
      "[3070]\ttrain-rmse:2252.71\teval-rmse:2488.96\n",
      "[3080]\ttrain-rmse:2251.8\teval-rmse:2488.76\n",
      "[3090]\ttrain-rmse:2251.03\teval-rmse:2488.65\n",
      "[3100]\ttrain-rmse:2250.2\teval-rmse:2488.5\n",
      "[3110]\ttrain-rmse:2249.49\teval-rmse:2488.46\n",
      "Stopping. Best iteration:\n",
      "[3106]\ttrain-rmse:2249.79\teval-rmse:2488.46\n",
      "\n",
      "train_rmse :2249.788232816847\t test_score:2488.456615406325\n"
     ]
    }
   ],
   "source": [
    "model_fold, fold_score, y_test_fold = manual_cv(train_X, train_y, test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: <xgboost.core.Booster at 0x137b472d588>,\n",
       " 1: <xgboost.core.Booster at 0x137b472d748>,\n",
       " 2: <xgboost.core.Booster at 0x137b472d240>}"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2491.9030071362276, 1: 2492.8776744604706, 2: 2488.456615406325}"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([14580.013, 10946.438,  7110.686, ..., 11031.276, 17750.178,\n",
       "         2613.072], dtype=float32),\n",
       " 1: array([15634.911 , 11220.359 ,  6894.729 , ...,  8840.743 , 18836.645 ,\n",
       "         2018.2335], dtype=float32),\n",
       " 2: array([15650.751 , 10321.371 ,  7314.3193, ...,  9467.656 , 18294.773 ,\n",
       "         2376.5637], dtype=float32)}"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(233599,)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_fold[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target = (y_test_fold[0] + y_test_fold[1] + y_test_fold[2])/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"Purchase\"] = y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['User_ID','Product_ID','Purchase']].to_csv('Solution.csv',columns = ['User_ID','Product_ID','Purchase'],index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000004</td>\n",
       "      <td>P00128942</td>\n",
       "      <td>15288.5590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000009</td>\n",
       "      <td>P00113442</td>\n",
       "      <td>10829.3900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000010</td>\n",
       "      <td>P00288442</td>\n",
       "      <td>7106.5780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000010</td>\n",
       "      <td>P00145342</td>\n",
       "      <td>2302.0996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000011</td>\n",
       "      <td>P00053842</td>\n",
       "      <td>1675.6019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID Product_ID    Purchase\n",
       "0  1000004  P00128942  15288.5590\n",
       "1  1000009  P00113442  10829.3900\n",
       "2  1000010  P00288442   7106.5780\n",
       "3  1000010  P00145342   2302.0996\n",
       "4  1000011  P00053842   1675.6019"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"data/Solution.csv\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (do_not)",
   "language": "python",
   "name": "do_not"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
